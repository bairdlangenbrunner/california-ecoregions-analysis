{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas\n",
    "import matplotlib.pyplot as mp\n",
    "import cartopy\n",
    "import numpy\n",
    "import xarray\n",
    "import shapely\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lon_lo, lon_hi, lat_lo, lat_hi = 234., 246.25, 32., 42.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "WHICH_ECOREGION = 4\n",
    "ECOREGION_NAME = 'sierra_nevada'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ca_eco_l3_gs = geopandas.GeoSeries.from_file('../ca_eco_l3/ca_eco_l3.shp')\n",
    "ca_eco_l3_gs = geopandas.GeoSeries.from_file('../ca_eco_l3/ca_eco_l3.shp') # import twice to get crs to work?...\n",
    "\n",
    "ecoregion_series = ca_eco_l3_gs.loc[WHICH_ECOREGION]\n",
    "\n",
    "ca_eco_l3_gs_4326 = ca_eco_l3_gs.to_crs({'init': 'epsg:4326'})\n",
    "ecoregion_series_geom_4326 = ca_eco_l3_gs_4326.loc[WHICH_ECOREGION]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ca_eco_l3_gdf = geopandas.read_file('../ca_eco_l3/ca_eco_l3.shp')\n",
    "ecoregion_names = ca_eco_l3_gdf['US_L3NAME']\n",
    "#print(ecoregion_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "open NetCDF4 CESM LENS data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open example\n",
    "\n",
    "root_dir = '../cesm-LE-file/'\n",
    "file_name = 'b.e11.B20TRC5CNBDRD.f09_g16.002.cam.h1.TS.19200101-20051231.nc'\n",
    "ncfile = xarray.open_dataset(root_dir + file_name)\n",
    "#ts_data = ncfile['TS'].sel(lat=slice(lat_lo,lat_hi),lon=slice(lon_lo,lon_hi)).values\n",
    "ts_lat = ncfile['lat'].sel(lat=slice(lat_lo,lat_hi)).values\n",
    "ts_lon = ncfile['lon'].sel(lon=slice(lon_lo,lon_hi)).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lon_pcolormesh = numpy.zeros(ts_lon.size+2)\n",
    "lon_pcolormesh[1:-1] = ts_lon\n",
    "lon_pcolormesh[0] = ts_lon[0]-numpy.diff(ts_lon)[0]\n",
    "lon_pcolormesh[-1] = ts_lon[-1]+numpy.diff(ts_lon)[-1]\n",
    "lon_pcolormesh_midpoints = lon_pcolormesh[:-1]+0.5*(numpy.diff(lon_pcolormesh))\n",
    "\n",
    "lat_pcolormesh = numpy.zeros(ts_lat.size+2)\n",
    "lat_pcolormesh[1:-1] = ts_lat\n",
    "lat_pcolormesh[0] = ts_lat[0]-numpy.diff(ts_lat)[0]\n",
    "lat_pcolormesh[-1] = ts_lat[-1]+numpy.diff(ts_lat)[-1]\n",
    "lat_pcolormesh_midpoints = lat_pcolormesh[:-1]+0.5*(numpy.diff(lat_pcolormesh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not dependent on actual data\n",
    "latlon_index_combos = numpy.array([i for i in itertools.product(range(ts_lat.size),range(ts_lon.size))])\n",
    "\n",
    "lat_polygon_hi_list = []\n",
    "lon_polygon_hi_list = []\n",
    "lat_polygon_lo_list = []\n",
    "lon_polygon_lo_list = []\n",
    "\n",
    "lon_list = []\n",
    "lat_list = []\n",
    "\n",
    "for latlon in latlon_index_combos:\n",
    "\n",
    "    lat_idx = latlon[0]\n",
    "    lon_idx = latlon[1]\n",
    "    \n",
    "    lon_list.append(ts_lon[latlon[1]])\n",
    "    lat_list.append(ts_lat[latlon[0]])\n",
    "\n",
    "    lon_polygon_hi_list.append(-360.+lon_pcolormesh_midpoints[lon_idx+1])\n",
    "    lon_polygon_lo_list.append(-360.+lon_pcolormesh_midpoints[lon_idx])\n",
    "\n",
    "    lat_polygon_hi_list.append(lat_pcolormesh_midpoints[lat_idx+1])\n",
    "    lat_polygon_lo_list.append(lat_pcolormesh_midpoints[lat_idx])\n",
    "\n",
    "polygon_boxes = numpy.array([shapely.geometry.box(i[0],i[1],i[2],i[3]) \\\n",
    "                             for i in zip(lon_polygon_lo_list,lat_polygon_lo_list, \\\n",
    "                                          lon_polygon_hi_list,lat_polygon_hi_list)])\n",
    "\n",
    "# calculate True/False intersection list of these projected ecoregion polygons\n",
    "intersects_TF_list = []\n",
    "for box in polygon_boxes:\n",
    "    intersects_TF_list.append(ecoregion_series_geom_4326.intersects(box))\n",
    "latlon_index_combos_intersect = latlon_index_combos[intersects_TF_list]\n",
    "\n",
    "# calculates percent area overlap\n",
    "#for box in polygon_boxes[intersects_TF_list]:\n",
    "#    print('{:.2f}'.format(ecoregion_series_geom_4326.intersection(box).area/box.area))\n",
    "\n",
    "# create mask of NaNs and fractional values\n",
    "mask_and_weights = numpy.zeros((ts_lat.size,ts_lon.size))*numpy.nan\n",
    "for i,latlon in enumerate(latlon_index_combos_intersect):\n",
    "    mask_and_weights[latlon[0],latlon[1]] = ecoregion_series_geom_4326.intersection(polygon_boxes[intersects_TF_list][i]).area/polygon_boxes[intersects_TF_list][i].area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b.e11.B20TRC5CNBDRD.f09_g16.002.cam.h1.TS.19200101-20051231.nc\n"
     ]
    }
   ],
   "source": [
    "# loop through all ts data\n",
    "\n",
    "file_name_list = ['b.e11.B20TRC5CNBDRD.f09_g16.002.cam.h1.TS.19200101-20051231.nc']\n",
    "\n",
    "for file_name in file_name_list:\n",
    "\n",
    "    print(file_name)\n",
    "    ts_data = xarray.open_dataset(root_dir + file_name)['TS'].sel(lat=slice(lat_lo,lat_hi),lon=slice(lon_lo,lon_hi)).values\n",
    "    \n",
    "    # now calculations weighting calculations\n",
    "    weighted_ecoregion_ts_mean = numpy.nansum(mask_and_weights*ts_data, axis=(1,2))/numpy.nansum(mask_and_weights)\n",
    "    time_data = ncfile['time']\n",
    "\n",
    "    ts_data_array = xarray.DataArray(weighted_ecoregion_ts_mean, coords=[time_data], dims=['time'])\n",
    "\n",
    "    run_type = file_name.split('.')[2]\n",
    "    date_range = file_name.split('.')[8]\n",
    "    simulation_index = file_name.split('.')[4]\n",
    "\n",
    "    attr_dict = {}\n",
    "    attr_dict['units'] = 'Kelvin'\n",
    "    attr_dict['LENS ensemble number'] = simulation_index\n",
    "    ts_data_array.attrs = attr_dict\n",
    "\n",
    "    data_set = xarray.Dataset({'TS': (['time'], ts_data_array)}, coords={'time': (['time'], time_data)})\n",
    "    data_set.to_netcdf('LENS_run_'+simulation_index+'_'+ECOREGION_NAME+'_'+run_type+'_'+date_range+'.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
