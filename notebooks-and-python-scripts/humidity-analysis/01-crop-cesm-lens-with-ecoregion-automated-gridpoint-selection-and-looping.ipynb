{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas\n",
    "import matplotlib.pyplot as mp\n",
    "import cartopy\n",
    "import numpy\n",
    "import xarray\n",
    "import shapely\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lon_lo, lon_hi, lat_lo, lat_hi = 234., 246.25, 32., 42.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "WHICH_ECOREGION = 4\n",
    "ECOREGION_NAME = 'sierra_nevada'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "DriverError",
     "evalue": "../ca_eco_l3/ca_eco_l3.shp: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCPLE_OpenFailedError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32mfiona/_shim.pyx\u001b[0m in \u001b[0;36mfiona._shim.gdal_open_vector\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mfiona/_err.pyx\u001b[0m in \u001b[0;36mfiona._err.exc_wrap_pointer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mCPLE_OpenFailedError\u001b[0m: ../ca_eco_l3/ca_eco_l3.shp: No such file or directory",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mDriverError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-187343dc4e03>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mca_eco_l3_gs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgeopandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGeoSeries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../ca_eco_l3/ca_eco_l3.shp'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mca_eco_l3_gs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgeopandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGeoSeries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../ca_eco_l3/ca_eco_l3.shp'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# import twice to get crs to work?...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mecoregion_series\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mca_eco_l3_gs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mWHICH_ECOREGION\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/geopandas/geoseries.py\u001b[0m in \u001b[0;36mfrom_file\u001b[0;34m(cls, filename, **kwargs)\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mimport\u001b[0m \u001b[0mfiona\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0mgeoms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mfiona\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m             \u001b[0mcrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mrec\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/fiona/env.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    403\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mEnv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_defaults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m                 \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Credentialized: {!r}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetenv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/fiona/__init__.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, driver, schema, crs, encoding, layer, vfs, enabled_drivers, crs_wkt, **kwargs)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             c = Collection(path, mode, driver=driver, encoding=encoding,\n\u001b[0;32m--> 253\u001b[0;31m                            layer=layer, enabled_drivers=enabled_drivers, **kwargs)\n\u001b[0m\u001b[1;32m    254\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/fiona/collection.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path, mode, driver, schema, crs, encoding, layer, vsi, archive, enabled_drivers, crs_wkt, ignore_fields, ignore_geometry, **kwargs)\u001b[0m\n\u001b[1;32m    157\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWritingSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mfiona/ogrext.pyx\u001b[0m in \u001b[0;36mfiona.ogrext.Session.start\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mfiona/_shim.pyx\u001b[0m in \u001b[0;36mfiona._shim.gdal_open_vector\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mDriverError\u001b[0m: ../ca_eco_l3/ca_eco_l3.shp: No such file or directory"
     ]
    }
   ],
   "source": [
    "ca_eco_l3_gs = geopandas.GeoSeries.from_file('../ca_eco_l3/ca_eco_l3.shp')\n",
    "ca_eco_l3_gs = geopandas.GeoSeries.from_file('../ca_eco_l3/ca_eco_l3.shp') # import twice to get crs to work?...\n",
    "\n",
    "ecoregion_series = ca_eco_l3_gs.loc[WHICH_ECOREGION]\n",
    "\n",
    "ca_eco_l3_gs_4326 = ca_eco_l3_gs.to_crs({'init': 'epsg:4326'})\n",
    "ecoregion_series_geom_4326 = ca_eco_l3_gs_4326.loc[WHICH_ECOREGION]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ca_eco_l3_gdf = geopandas.read_file('../ca_eco_l3/ca_eco_l3.shp')\n",
    "ecoregion_names = ca_eco_l3_gdf['US_L3NAME']\n",
    "#print(ecoregion_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "open NetCDF4 CESM LENS data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open example\n",
    "\n",
    "root_dir = '../cesm-LE-file/'\n",
    "file_name = 'b.e11.B20TRC5CNBDRD.f09_g16.002.cam.h1.TS.19200101-20051231.nc'\n",
    "ncfile = xarray.open_dataset(root_dir + file_name)\n",
    "#ts_data = ncfile['TS'].sel(lat=slice(lat_lo,lat_hi),lon=slice(lon_lo,lon_hi)).values\n",
    "ts_lat = ncfile['lat'].sel(lat=slice(lat_lo,lat_hi)).values\n",
    "ts_lon = ncfile['lon'].sel(lon=slice(lon_lo,lon_hi)).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lon_pcolormesh = numpy.zeros(ts_lon.size+2)\n",
    "lon_pcolormesh[1:-1] = ts_lon\n",
    "lon_pcolormesh[0] = ts_lon[0]-numpy.diff(ts_lon)[0]\n",
    "lon_pcolormesh[-1] = ts_lon[-1]+numpy.diff(ts_lon)[-1]\n",
    "lon_pcolormesh_midpoints = lon_pcolormesh[:-1]+0.5*(numpy.diff(lon_pcolormesh))\n",
    "\n",
    "lat_pcolormesh = numpy.zeros(ts_lat.size+2)\n",
    "lat_pcolormesh[1:-1] = ts_lat\n",
    "lat_pcolormesh[0] = ts_lat[0]-numpy.diff(ts_lat)[0]\n",
    "lat_pcolormesh[-1] = ts_lat[-1]+numpy.diff(ts_lat)[-1]\n",
    "lat_pcolormesh_midpoints = lat_pcolormesh[:-1]+0.5*(numpy.diff(lat_pcolormesh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not dependent on actual data\n",
    "latlon_index_combos = numpy.array([i for i in itertools.product(range(ts_lat.size),range(ts_lon.size))])\n",
    "\n",
    "lat_polygon_hi_list = []\n",
    "lon_polygon_hi_list = []\n",
    "lat_polygon_lo_list = []\n",
    "lon_polygon_lo_list = []\n",
    "\n",
    "lon_list = []\n",
    "lat_list = []\n",
    "\n",
    "for latlon in latlon_index_combos:\n",
    "\n",
    "    lat_idx = latlon[0]\n",
    "    lon_idx = latlon[1]\n",
    "    \n",
    "    lon_list.append(ts_lon[latlon[1]])\n",
    "    lat_list.append(ts_lat[latlon[0]])\n",
    "\n",
    "    lon_polygon_hi_list.append(-360.+lon_pcolormesh_midpoints[lon_idx+1])\n",
    "    lon_polygon_lo_list.append(-360.+lon_pcolormesh_midpoints[lon_idx])\n",
    "\n",
    "    lat_polygon_hi_list.append(lat_pcolormesh_midpoints[lat_idx+1])\n",
    "    lat_polygon_lo_list.append(lat_pcolormesh_midpoints[lat_idx])\n",
    "\n",
    "polygon_boxes = numpy.array([shapely.geometry.box(i[0],i[1],i[2],i[3]) \\\n",
    "                             for i in zip(lon_polygon_lo_list,lat_polygon_lo_list, \\\n",
    "                                          lon_polygon_hi_list,lat_polygon_hi_list)])\n",
    "\n",
    "# calculate True/False intersection list of these projected ecoregion polygons\n",
    "intersects_TF_list = []\n",
    "for box in polygon_boxes:\n",
    "    intersects_TF_list.append(ecoregion_series_geom_4326.intersects(box))\n",
    "latlon_index_combos_intersect = latlon_index_combos[intersects_TF_list]\n",
    "\n",
    "# calculates percent area overlap\n",
    "#for box in polygon_boxes[intersects_TF_list]:\n",
    "#    print('{:.2f}'.format(ecoregion_series_geom_4326.intersection(box).area/box.area))\n",
    "\n",
    "# create mask of NaNs and fractional values\n",
    "mask_and_weights = numpy.zeros((ts_lat.size,ts_lon.size))*numpy.nan\n",
    "for i,latlon in enumerate(latlon_index_combos_intersect):\n",
    "    mask_and_weights[latlon[0],latlon[1]] = ecoregion_series_geom_4326.intersection(polygon_boxes[intersects_TF_list][i]).area/polygon_boxes[intersects_TF_list][i].area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b.e11.B20TRC5CNBDRD.f09_g16.002.cam.h1.TS.19200101-20051231.nc\n"
     ]
    }
   ],
   "source": [
    "# loop through all ts data\n",
    "\n",
    "file_name_list = ['b.e11.B20TRC5CNBDRD.f09_g16.002.cam.h1.TS.19200101-20051231.nc']\n",
    "\n",
    "for file_name in file_name_list:\n",
    "\n",
    "    print(file_name)\n",
    "    ts_data = xarray.open_dataset(root_dir + file_name)['TS'].sel(lat=slice(lat_lo,lat_hi),lon=slice(lon_lo,lon_hi)).values\n",
    "    \n",
    "    # now calculations weighting calculations\n",
    "    weighted_ecoregion_ts_mean = numpy.nansum(mask_and_weights*ts_data, axis=(1,2))/numpy.nansum(mask_and_weights)\n",
    "    time_data = ncfile['time']\n",
    "\n",
    "    ts_data_array = xarray.DataArray(weighted_ecoregion_ts_mean, coords=[time_data], dims=['time'])\n",
    "\n",
    "    run_type = file_name.split('.')[2]\n",
    "    date_range = file_name.split('.')[8]\n",
    "    simulation_index = file_name.split('.')[4]\n",
    "\n",
    "    attr_dict = {}\n",
    "    attr_dict['units'] = 'Kelvin'\n",
    "    attr_dict['LENS ensemble number'] = simulation_index\n",
    "    ts_data_array.attrs = attr_dict\n",
    "\n",
    "    data_set = xarray.Dataset({'TS': (['time'], ts_data_array)}, coords={'time': (['time'], time_data)})\n",
    "    data_set.to_netcdf('LENS_run_'+simulation_index+'_'+ECOREGION_NAME+'_'+run_type+'_'+date_range+'.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
